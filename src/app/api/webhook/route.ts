import { NextRequest, NextResponse } from 'next/server'
import { CastService } from '@/lib/supabase'
import type { SavedCast } from '@/lib/supabase'

/**
 * Required Environment Variables for Bot Replies:
 * - NEYNAR_API_KEY: Your Neynar API key for posting casts
 * - NEYNAR_SIGNER_UUID: Signer UUID for the bot account
 * - OPENAI_API_KEY: OpenAI API key for cast comprehension
 * 
 * Without these, the bot will process mentions but won't reply to casts.
 */

// Type definitions for webhook payload
interface CastAuthor {
  fid?: number
  username?: string
  display_name?: string
  pfp_url?: string
}

interface WebhookCast {
  text: string
  hash?: string  // Current cast hash
  parent_hash?: string
  parent_author?: CastAuthor
  author: CastAuthor
  mentioned_profiles?: Array<{ username?: string; fid?: number }>
}

export async function POST(request: NextRequest) {
  try {
    console.log('ğŸ¯ Webhook received!')
    
    const body = await request.json()
    console.log('ğŸ“¦ Webhook payload received')
    
    // Check event type
    if (body.type !== 'cast.created') {
      console.log('âŒ Not a cast.created event, skipping')
      return NextResponse.json({ message: 'Event type not handled' })
    }
    
    const cast: WebhookCast = body.data
    console.log('ğŸ“ Processing cast from:', cast.author.username)
    
    // Check for mentions
    const mentions = cast.mentioned_profiles || []
    const mentionsBot = mentions.some((profile: { username?: string; fid?: number }) => {
      return profile.username === 'cstkpr'
    })
    
    console.log('ğŸ¤– Bot mentioned?', mentionsBot)
    
    if (!mentionsBot) {
      console.log('âŒ Bot not mentioned, skipping')
      return NextResponse.json({ message: 'Bot not mentioned' })
    }
    
    // Process the bot mention
    const text = cast.text.toLowerCase()
    const userId = cast.author.username ?? 'unknown-user'
    const parentHash = cast.parent_hash ?? null
    
    console.log('ğŸ’¬ Cast text:', text)
    console.log('ğŸ‘¤ User ID:', userId)
    console.log('ğŸ‘† Parent hash:', parentHash)
    
    // Generate response for any bot mention
    const { commandType, response, contextData } = await generateBotResponse(text, userId, parentHash, cast)
    
    // Post reply to Farcaster (reply to the cast that mentioned the bot)
    const castHash = cast.hash || body.data?.hash
    console.log('ğŸ”— Cast hash for reply:', castHash)
    
    if (castHash) {
      await postReplyToFarcaster(response, cast.author.fid || 0, castHash)
    } else {
      console.error('âŒ No cast hash found to reply to')
      console.log('ğŸ“‹ Available cast data:', Object.keys(cast))
      console.log('ğŸ“‹ Available body.data:', Object.keys(body.data || {}))
    }
    
    // Save the conversation using regular service
    try {
      if (commandType === 'save' && contextData) {
        const savedCast = await CastService.saveCast(contextData)
        console.log('âœ… Cast saved successfully:', savedCast.cast_hash)
        
        return NextResponse.json({ 
          success: true, 
          message: 'Cast saved and reply posted',
          cast_id: savedCast.cast_hash,
          saved_cast_id: savedCast.id,
          response,
          command_type: commandType
        })
      } else {
        // For non-save commands (help, stats, conversation, general), just return the response
        console.log(`ğŸ¤– Bot responding with ${commandType}: ${response}`)
        return NextResponse.json({ 
          success: true, 
          message: 'Reply posted successfully',
          response,
          command_type: commandType
        })
      }
      
    } catch (saveError) {
      console.error('âŒ Error saving cast:', saveError)
      const errorMessage = saveError instanceof Error ? saveError.message : 'Unknown error'
      console.error('âŒ Save error details:', errorMessage)
      return NextResponse.json({ 
        error: 'Failed to save cast', 
        details: errorMessage 
      }, { status: 500 })
    }
    
  } catch (webhookError) {
    console.error('ğŸ’¥ Webhook error:', webhookError)
    const errorMessage = webhookError instanceof Error ? webhookError.message : 'Unknown error'
    console.error('ğŸ’¥ Webhook error details:', errorMessage)
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}

// Helper function to generate bot responses
async function generateBotResponse(
  text: string, 
  userId: string, 
  parentHash: string | null,
  cast: WebhookCast
): Promise<{
  commandType: string;
  response: string;
  contextData?: Omit<SavedCast, 'id' | 'created_at' | 'updated_at'>;
}> {
  const lowerText = text.toLowerCase()
  
  // Save commands
  if (lowerText.includes('save this') || (lowerText.includes('save') && !lowerText.includes('what do you think'))) {
    if (!parentHash) {
      return {
        commandType: 'save_error',
        response: 'No cast to save found. Please reply to a cast you want to save.'
      }
    }
    
    // Create cast data for saving
    const castData = {
      username: `user-${cast.parent_author?.fid || 'unknown'}`,
      fid: cast.parent_author?.fid || 0,
      cast_hash: parentHash,
      cast_content: `ğŸ”— Cast saved from Farcaster - Hash: ${parentHash}`,
      cast_timestamp: new Date().toISOString(),
      tags: ['saved-via-bot'] as string[],
      likes_count: 0,
      replies_count: 0,
      recasts_count: 0,
      cast_url: `https://warpcast.com/~/conversations/${parentHash}`,
      author_pfp_url: undefined,
      author_display_name: `User ${cast.parent_author?.fid || 'Unknown'}`,
      saved_by_user_id: userId,
      category: 'saved-via-bot',
      notes: `ğŸ’¾ Saved via @cstkpr bot by ${userId} on ${new Date().toLocaleDateString()}`,
      parsed_data: {
        urls: [`https://warpcast.com/~/conversations/${parentHash}`],
        hashtags: ['cstkpr', 'saved'],
        mentions: ['cstkpr'],
        word_count: 0,
        sentiment: 'neutral' as const,
        topics: ['saved-cast']
      }
    } satisfies Omit<SavedCast, 'id' | 'created_at' | 'updated_at'>
    
    return {
      commandType: 'save',
      response: 'âœ… Cast saved successfully! You can view it at castkpr.vercel.app',
      contextData: castData
    }
  }
  
  // Help command
  if (lowerText.includes('help')) {
    return {
      commandType: 'help',
      response: `ğŸ¤– CastKPR Bot Commands:
      
â€¢ Reply "save this" to any cast to save it
â€¢ "help" - Show this help message  
â€¢ "stats" - View your save statistics
â€¢ Ask me what I think about anything!

Visit castkpr.vercel.app to view all your saved casts!`
    }
  }
  
  // Stats command
  if (lowerText.includes('stats')) {
    try {
      const stats = await CastService.getUserStats(userId)
      return {
        commandType: 'stats',
        response: `ğŸ“Š Your CastKPR Stats:

â€¢ Total saved casts: ${stats.totalCasts}

Visit castkpr.vercel.app to explore your collection!`
      }
    } catch (statsError) {
      console.error('Error fetching stats:', statsError)
      return {
        commandType: 'stats_error',
        response: 'Unable to fetch stats right now. Try again later!'
      }
    }
  }
  
  // Conversational responses for opinion questions - now with AI comprehension
  if (lowerText.includes('what do you think') || 
      lowerText.includes('your thoughts') || 
      lowerText.includes('do you agree') || 
      lowerText.includes('do you disagree') ||
      lowerText.includes('what are your thoughts') ||
      lowerText.includes('thoughts?') ||
      lowerText.includes('opinion') ||
      lowerText.includes('take on this') ||
      lowerText.includes('what\'s your take') ||
      lowerText.includes('how do you feel')) {
    
    // Get the cast content to analyze
    const castToAnalyze = parentHash ? 
      await getCastContent(parentHash) : 
      cast.text
    
    if (castToAnalyze) {
      const aiResponse = await generateAIResponse(castToAnalyze, text)
      return {
        commandType: 'conversation',
        response: aiResponse
      }
    }
    
    // Fallback to generic response if no content found
    const responses = [
      "ğŸ¤” Interesting perspective! I think there's always multiple angles to consider. What's your take?",
      "ğŸ’­ That's thought-provoking! As a cast-saving bot, I see all kinds of takes. This one's worth saving! Try 'save this' ğŸ˜‰",
      "ğŸ§  Great question! I process a lot of conversations and this feels like one worth keeping track of."
    ]
    
    const randomResponse = responses[Math.floor(Math.random() * responses.length)]
    
    return {
      commandType: 'conversation',
      response: randomResponse
    }
  }
  
  // Agreement/disagreement responses - now with AI comprehension
  if (lowerText.includes('agree') || lowerText.includes('disagree')) {
    // Get the cast content to analyze
    const castToAnalyze = parentHash ? 
      await getCastContent(parentHash) : 
      cast.text
    
    if (castToAnalyze) {
      const aiResponse = await generateAIResponse(castToAnalyze, text)
      return {
        commandType: 'conversation',
        response: aiResponse
      }
    }
    
    // Fallback responses
    const responses = [
      "ğŸ¤ I see both sides! That's what makes discussions interesting.",
      "âš–ï¸ Truth usually lies somewhere in the middle. What made you lean that way?",
      "ğŸ§© Every perspective adds a piece to the puzzle. Thanks for sharing yours!"
    ]
    
    const randomResponse = responses[Math.floor(Math.random() * responses.length)]
    
    return {
      commandType: 'conversation',
      response: randomResponse
    }
  }
  
  // Default response for general mentions - now with AI comprehension
  const castToAnalyze = parentHash ? 
    await getCastContent(parentHash) : 
    cast.text

  if (castToAnalyze && lowerText.length > 10) { // Only use AI for substantial mentions
    const aiResponse = await generateAIResponse(castToAnalyze, text)
    return {
      commandType: 'general',
      response: aiResponse
    }
  }

  // Fallback response for simple mentions
  return {
    commandType: 'general',
    response: `ğŸ¤– Hey! I'm CastKPR, your cast-saving companion. 

I can help you save great conversations for later! Just reply "save this" to any cast you want to keep, or ask me what I think about anything.

Visit castkpr.vercel.app to browse your saved collection! ğŸ’œ`
  }
}

// Function to post reply to Farcaster
async function postReplyToFarcaster(message: string, parentAuthorFid: number, parentCastHash: string): Promise<void> {
  try {
    console.log('ğŸ“¤ Attempting to post reply to Farcaster...')
    
    // Check if we have the required environment variables
    const neynarApiKey = process.env.NEYNAR_API_KEY
    const signerUuid = process.env.NEYNAR_SIGNER_UUID
    
    if (!neynarApiKey || !signerUuid) {
      console.error('âŒ Missing required environment variables for posting')
      console.error('Need: NEYNAR_API_KEY and NEYNAR_SIGNER_UUID')
      return
    }
    
    // Post the reply using Neynar API
    const response = await fetch('https://api.neynar.com/v2/farcaster/cast', {
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'api_key': neynarApiKey,
      },
      body: JSON.stringify({
        signer_uuid: signerUuid,
        text: message,
        parent: parentCastHash,
      }),
    })
    
    if (response.ok) {
      const result = await response.json()
      console.log('âœ… Successfully posted reply to Farcaster:', result.cast.hash)
    } else {
      const errorText = await response.text()
      console.error('âŒ Failed to post reply:', response.status, errorText)
    }
    
  } catch (postError) {
    console.error('ğŸ’¥ Error posting reply to Farcaster:', postError)
  }
}

// Function to get cast content from Neynar API
async function getCastContent(castHash: string): Promise<string | null> {
  try {
    const neynarApiKey = process.env.NEYNAR_API_KEY
    
    if (!neynarApiKey) {
      console.error('âŒ Missing NEYNAR_API_KEY for fetching cast content')
      return null
    }
    
    const response = await fetch(`https://api.neynar.com/v2/farcaster/cast?identifier=${castHash}&type=hash`, {
      method: 'GET',
      headers: {
        'Accept': 'application/json',
        'api_key': neynarApiKey,
      },
    })
    
    if (response.ok) {
      const result = await response.json()
      return result.cast.text || null
    } else {
      console.error('âŒ Failed to fetch cast content:', response.status)
      return null
    }
    
  } catch (fetchError) {
    console.error('ğŸ’¥ Error fetching cast content:', fetchError)
    return null
  }
}

// Function to generate AI response based on cast content
async function generateAIResponse(castContent: string, userMessage: string): Promise<string> {
  try {
    const openaiApiKey = process.env.OPENAI_API_KEY
    
    if (!openaiApiKey) {
      console.error('âŒ Missing OPENAI_API_KEY for AI responses')
      return "ğŸ¤– I'd love to share my thoughts, but I need my AI capabilities configured! For now, this seems like great content worth saving."
    }
    
    const prompt = `You are CastKPR, a helpful and engaging Farcaster bot that helps people save and discuss casts. 

Someone shared this cast: "${castContent}"

They asked you: "${userMessage}"

Please respond in a thoughtful, conversational way that:
- Shows you understand the cast content
- Gives a genuine, helpful perspective 
- Stays under 280 characters
- Uses emojis appropriately
- Occasionally mentions that great content like this is worth saving with "save this"
- Maintains a friendly, knowledgeable tone

Don't be overly promotional about saving casts - just be helpful and engaging.`

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: 'You are CastKPR, a helpful Farcaster bot that helps save and discuss casts. Be conversational, insightful, and under 280 characters.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 150,
        temperature: 0.7,
      }),
    })
    
    if (response.ok) {
      const result = await response.json()
      const aiResponse = result.choices[0]?.message?.content?.trim() || ''
      
      // Ensure response is under 280 characters
      if (aiResponse.length > 280) {
        return aiResponse.substring(0, 277) + '...'
      }
      
      return aiResponse
    } else {
      console.error('âŒ Failed to generate AI response:', response.status)
      return "ğŸ¤– That's really interesting! I'm having trouble with my analysis right now, but this seems like quality content worth discussing."
    }
    
  } catch (aiError) {
    console.error('ğŸ’¥ Error generating AI response:', aiError)
    return "ğŸ¤– Fascinating topic! My circuits are a bit overloaded right now, but I can tell this is the kind of content worth keeping track of."
  }
}